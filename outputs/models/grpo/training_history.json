{
  "loss": [
    -2.431159036131203,
    -8.591307575523853
  ],
  "policy_loss": [
    -2.6339693708233534,
    -8.79577255153656
  ],
  "kl": [
    2.0281033411741256,
    2.0446497734308244
  ],
  "reward": [
    -2.1708422076284886,
    -2.141263950794935
  ],
  "reward_std": [
    2.1681234885573386,
    2.187549567592144
  ],
  "eval_reward": [
    -2.821937733069062,
    -2.3681074357777834,
    -2.310921210348606
  ],
  "eval_kl": [
    0.0,
    1.7058564710617066,
    1.9473209714889526
  ],
  "efficiency": {
    "total_training_time": 5736.635930776596,
    "total_samples_generated": 80000,
    "time_per_sample": 0.07170794913470745,
    "avg_time_per_iteration": 1.1473271861553191,
    "memory_peak_gb": 17.262200832
  }
}